{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1guZHw7-sXywZ-hdAZr4dpbN5MVG6KPrv","timestamp":1712971447005}],"authorship_tag":"ABX9TyNm23Xbgj12XgY79YlvIIuQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["The section installs, and configures Apache Hadoop version 3.3.6 in the Google Colab environment.\n","\n","This following series of commands downloads Apache Hadoop version 3.3.6 from the official Apache website, then extracts the downloaded file and moves it to the `/usr/local` directory. The `readlink` command with `sed` is used to find the default Java path, which is then assigned to the `JAVA_HOME` environment variable. After that, the `JAVA_HOME` variable is echoed to confirm the assignment. Finally, the `PATH` environment variable is updated to include the Hadoop binaries directory, ensuring that Hadoop commands can be executed from any location in the Colab environment."],"metadata":{"id":"MHmdTVQbzXxw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"sNLVRDOcroJy"},"outputs":[],"source":["!wget https://downloads.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz"]},{"cell_type":"code","source":["!tar -xzf hadoop-3.3.6.tar.gz"],"metadata":{"id":"Bwe2TwpXr3R-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp -r hadoop-3.3.6 /usr/local"],"metadata":{"id":"IYSzY6c3r_xz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#To find the default Java path\n","!readlink -f /usr/bin/java | sed \"s:bin/java::\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_K8oJUaVsGcJ","executionInfo":{"status":"ok","timestamp":1713106290423,"user_tz":-60,"elapsed":12,"user":{"displayName":"MA","userId":"16618968303950307685"}},"outputId":"849a6009-3ff1-4696-e26f-c002b010c15a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/lib/jvm/java-11-openjdk-amd64/\n"]}]},{"cell_type":"code","source":["import os\n","# BEGIN YOUR CODE HERE\n","\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64/\""],"metadata":{"id":"kuUWmp-NsKI-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!echo $JAVA_HOME"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RSlcX-V8sPl_","executionInfo":{"status":"ok","timestamp":1713106299358,"user_tz":-60,"elapsed":322,"user":{"displayName":"MA","userId":"16618968303950307685"}},"outputId":"52a4d1da-b9bf-4a90-abbd-1fe5fd920cbe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/lib/jvm/java-11-openjdk-amd64/\n"]}]},{"cell_type":"markdown","source":["=\n","\n","\n","\n","="],"metadata":{"id":"WR1Wes81sUqc"}},{"cell_type":"code","source":["import os\n","os.environ['PATH'] += ':/usr/local/hadoop-3.3.6/bin'"],"metadata":{"id":"mVGgrB8MsW-l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!echo $PATH"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rpu61SYksav7","executionInfo":{"status":"ok","timestamp":1713106308072,"user_tz":-60,"elapsed":291,"user":{"displayName":"MA","userId":"16618968303950307685"}},"outputId":"2a9cd05e-8a1e-4a25-8911-869dfa390e3a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/usr/local/hadoop-3.3.6/bin\n"]}]},{"cell_type":"markdown","source":[" **# MapReduce Operation**\n"],"metadata":{"id":"GkEpXLsJshAw"}},{"cell_type":"markdown","source":["Testing the Mapper and see its output. The code below will show the first 10 rows of the Mapper output."],"metadata":{"id":"TjuYRTyBusQc"}},{"cell_type":"code","source":["!head -n 10 motorcycle_accidents_test.csv | python mapper.py\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JpS7wf5mIcE6","executionInfo":{"status":"ok","timestamp":1713116983298,"user_tz":-60,"elapsed":390,"user":{"displayName":"MA","userId":"16618968303950307685"}},"outputId":"ff34190c-321a-4f95-d764-126266a1e314"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["BROOKLYN\t0\t0\n","BROOKLYN\t0\t0\n","BRONX\t0\t2\n","BROOKLYN\t0\t0\n","MANHATTAN\t0\t0\n","QUEENS\t0\t0\n","QUEENS\t0\t2\n","BROOKLYN\t0\t0\n","BROOKLYN\t0\t4\n","BRONX\t0\t1\n"]}]},{"cell_type":"markdown","source":["The code below is a MapReduce operation. This command executes a Hadoop MapReduce job using the specified Python scripts (`mapper.py` and `reducer.py`). It processes input data from the file `motorcycle_accidents_test.csv`, performs mapping and reducing tasks based on the provided scripts, and stores the output in the directory `/content/output1`."],"metadata":{"id":"xYieCj0Zvejq"}},{"cell_type":"code","source":["!hadoop jar /usr/local/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar  -files /content/mapper.py,/content/reducer.py -input /content/motorcycle_accidents_test.csv -output /content/output1 -mapper 'python mapper.py'  -reducer 'python reducer.py'"],"metadata":{"id":"TzZqmAoV7bEN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The MapReduce operation completed successfully; however, upon inspecting the output .txt file, we found it to be empty. To troubleshoot this issue, we edit the \"reducer\" script, which includes debugging code to pinpoint the source of the problem. The following reducer will store the output in the directory /content/output2."],"metadata":{"id":"h6oaOESkwTpq"}},{"cell_type":"code","source":["!hadoop jar /usr/local/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar  -files /content/mapper.py,/content/reducer2.py -input /content/motorcycle_accidents_test.csv -output /content/output2 -mapper 'python mapper.py'  -reducer 'python reducer2.py'"],"metadata":{"id":"0MVCALQWsjr2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The next and final reducer script was written after the debugging reducer, it does not have debugging code in it and just sucessfully outputs the desried results from the mapper into /content/output3"],"metadata":{"id":"2UbR5-22EcTE"}},{"cell_type":"code","source":["!hadoop jar /usr/local/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar  -files /content/mapper.py,/content/reducer3.py -input /content/motorcycle_accidents_test.csv -output /content/output3 -mapper 'python mapper.py'  -reducer 'python reducer3.py'"],"metadata":{"id":"Cz5CHv6K8Pa_"},"execution_count":null,"outputs":[]}]}